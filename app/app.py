import os
import joblib
import pickle
import sklearn
import numpy as np
import pandas as pd
import seaborn as sns
import streamlit as st
from datetime import datetime
import plotly.express as px
from datetime import datetime
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Configuration de la page Streamlit
st.set_page_config(
    page_title="üî¨ Medical Report Classification Using NLP and Machine Learning",  # Titre de la page
    page_icon="ü©∫",  # Ic√¥ne affich√©e dans l'onglet du navigateur
    layout="wide"  # Mise en page large pour maximiser l'espace
)

# Titre de l'application avec emojis
st.title("üî¨ Medical Report Classification Using NLP and Machine Learning")
st.markdown("### üìÇ **Mantu - Data Science Technical Assessment**")

# Fonction pour afficher la barre lat√©rale
def display_sidebar():
    st.sidebar.header("üî¨ **Classification de Rapports M√©dicaux**")
    
    # Affichage de l'image de l'entreprise
    st.sidebar.image(
        'https://careers.mantu.com/build/assets/Mantu-careers_thumbnail-X-b281b1af.png', 
        use_container_width=True
    )
    
    # Informations sur la version de l'application
    st.sidebar.markdown(
        """
        <div style="text-align: center; font-size: 18px; font-weight: bold; margin-top: 10px; color: #000000;">
            üìÖ Version de l'application : 2.0.0
        </div>
        """, 
        unsafe_allow_html=True
    )
    
    # Informations sur le projet
    st.sidebar.markdown(
        """
        <hr style="margin-top: 10px; margin-bottom: 10px; border: 1px solid #ddd;" />
        <h3 style="text-align: center; font-size: 20px; color: #000000;">
            üìù Informations sur le projet
        </h3>
        <div style="font-size: 16px; line-height: 1.6; color: #000000;">
            <b>üë®‚Äçüíª Auteur :</b> Rostand Surel<br/>
            <b>üóìÔ∏è Date de cr√©ation :</b> {creation_date}<br/>
            <b>üîÑ Derni√®re mise √† jour :</b> {last_update}<br/>
            <b>üìÇ Code source :</b> <a href="https://github.com/Manda404" target="_blank" style="color: #000000;">GitHub</a><br/>
            <b>üîó Profil LinkedIn :</b> <a href="https://www.linkedin.com/in/rostand-surel/" target="_blank" style="color: #000000;">Voir le profil</a>
        </div>
        """.format(
            creation_date="2025-01-28",
            last_update=datetime.now().strftime("%Y-%m-%d")
        ), 
        unsafe_allow_html=True
    )
    
    # Lien vers des ressources utiles
    st.sidebar.markdown("""
    <hr style="border: 1px solid #ddd;">
    <h3 style="text-align: center; font-size: 18px; color: #000000;">üîó Ressources utiles</h3>
    <ul style="color: #000000;">
        <li><a href="https://scikit-learn.org/stable/" target="_blank" style="color: #000000;">Documentation Scikit-Learn</a></li>
        <li><a href="https://pandas.pydata.org/docs/" target="_blank" style="color: #000000;">Documentation Pandas</a></li>
        <li><a href="https://docs.streamlit.io/" target="_blank" style="color: #000000;">Documentation Streamlit</a></li>
    </ul>
    """, unsafe_allow_html=True)
    
    # S√©paration visuelle
    st.sidebar.markdown("---")

# Charger le dataset avec la nouvelle m√©thode de mise en cache
@st.cache_data
def load_dataset(file_path,nom_fichier='medical-abstracts-dataset.csv'):
    """
    :param file_path: Chemin vers le fichier CSV.
    :return: DataFrame Pandas contenant les donn√©es charg√©es.
    """
    try:
        # Charger le dataset
        data = pd.read_csv(os.path.join(file_path, nom_fichier))
        return data

    except FileNotFoundError:
        print(f"Erreur : le fichier sp√©cifi√© √† '{file_path}' est introuvable.")
        return None
    except pd.errors.EmptyDataError:
        print("Erreur : le fichier est vide.")
        return None
    except pd.errors.ParserError:
        print("Erreur : probl√®me de parsing lors de la lecture du fichier.")
        return None
    except Exception as e:
        print(f"Une erreur inattendue s'est produite : {e}")
        return None

# Fonction pour afficher la pr√©sentation en Markdown
def display_presentation():
    st.markdown(
        """
        ## **Project Objective**  
        
        ### üìÇ **Dataset**  
        - Analyze a dataset comprising **2,286 medical reports** extracted from a HuggingFace subset.  
        - Medical reports are classified into the following categories:  
          - **Neoplasms**  
          - **Digestive System Diseases**  
          - **Nervous System Diseases**  
          - **Cardiovascular Diseases**  
          - **General Pathological Conditions**  
        
        ### üéØ **Goal**  
        - Develop a **Python-based solution** capable of predicting the associated medical department for any given report.  
        
        ### üî¨ **Approach**  
        - Implement multiple **text classification techniques**, including but not limited to:  
          - Traditional machine learning algorithms (e.g., Logistic Regression, SVM).  
          - Deep learning models such as **LSTM**.  
          - Transformer-based models like **BERT** for state-of-the-art performance.  
        - Select and evaluate the **best-performing models** based on relevant metrics.  
        
        ### üõ† **Interface Streamlit**
        
        - The application is structured into four main tabs:
          1. **üè† Pr√©sentation** - Overview of the project and objectives.
          2. **üìà Exploratory Data Analysis** - Visual analysis and insights from the dataset.
          3. **üèãÔ∏è‚Äç‚ôÇÔ∏è Global Performance** - Evaluation of models and their performances.
          4. **üèÉ‚Äç‚ôÇÔ∏è Prediction** - Predict medical report categories using the best-trained model.
        
        - The **sidebar** contains:
          - The application logo and title.
          - Version information.
          - Project details such as author, creation date, and last update.
        
        - The main sections are displayed dynamically within the respective tabs, allowing for easy navigation and interaction.
        """
    )

# Initialiser `report_nouveau` dans st.session_state si ce n'est pas d√©j√† fait
if 'report_nouveau' not in st.session_state:
    st.session_state['report_nouveau'] = {
        'Accuracy': 0.0,
        'Precision': 0.0,
        'Recall': 0.0,
        'F1 Score': 0.0
    }

# Fonction pour lire le fichier CSV et retourner les donn√©es sous forme de dictionnaire
def lire_metrics(path, nom_fichier='metrics.csv'):
    """
    Lit le fichier CSV contenant les m√©triques et retourne les donn√©es sous forme de dictionnaire.
    
    Args:
        path (str): Le chemin du fichier CSV.
        nom_fichier (str): Le nom du fichier CSV (par d√©faut 'metrics.csv').
    
    Returns:
        dict: Les donn√©es du fichier CSV sous forme de dictionnaire.
    """
    # Cr√©er le chemin complet du fichier
    chemin_complet = os.path.join(path, nom_fichier)
    
    # Lire le fichier CSV
    df = pd.read_csv(chemin_complet)
    
    # Convertir le DataFrame en dictionnaire
    report_dict = df.to_dict(orient='records')[0]  # On prend le premier enregistrement
    return report_dict


# Fonction pour cr√©er une jauge circulaire
def create_gauge(name, value):
    fig = go.Figure(go.Indicator(
        mode="gauge+number+delta",
        value=value * 100,  # Conversion en pourcentage
        number={'suffix': "%"},
        title={'text': name, 'font': {'size': 20}},
        gauge={
            'axis': {'range': [0, 100], 'tickwidth': 1, 'tickcolor': "darkblue"},
            'bar': {'color': "darkblue"},
            'bgcolor': "white",
            'borderwidth': 2,
            'bordercolor': "gray",
            'steps': [
                {'range': [0, 50], 'color': 'lightgray'},
                {'range': [50, 100], 'color': 'lightgreen'}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': value * 100  # Conversion en pourcentage
            }
        },
        delta={'reference': 50, 'position': "top"}
    ))
    fig.update_layout(
        margin=dict(l=10, r=10, t=30, b=10),
        height=250,
        width=250
    )
    return fig

# Fonction principale pour l'affichage et la comparaison des performances
@st.cache_data
def display_global_performance(path_rapport):
    st.title("Performance Globale")
    st.subheader("M√©triques de performance")

    # Chargement des m√©triques actuelles
    report_actuelle = lire_metrics(path_rapport)

    # Cr√©ation des graphiques pour chaque m√©trique
    figures = [create_gauge(name, value) for name, value in report_actuelle.items()]

    with st.expander("D√©tails et explications des m√©triques", expanded=True):
        st.markdown("""
        **Accuracy (Exactitude)** ‚Äî Cette m√©trique mesure la proportion de pr√©dictions correctes parmi toutes les pr√©dictions effectu√©es.
        """, unsafe_allow_html=True)
        st.markdown("""
        **Precision (Pr√©cision)** ‚Äî Cette m√©trique mesure la proportion de pr√©dictions positives correctes parmi toutes les pr√©dictions positives faites par le mod√®le.
        """, unsafe_allow_html=True)
        st.markdown("""
        **Recall (Rappel)** ‚Äî Aussi appel√© sensibilit√©, le rappel mesure la proportion d'instances positives r√©elles qui ont √©t√© correctement identifi√©es par le mod√®le.
        """, unsafe_allow_html=True)
        st.markdown("""
        **F1 Score** ‚Äî La moyenne harmonique de la pr√©cision et du rappel, qui √©quilibre les deux m√©triques. Il est utile lorsqu'il est important de trouver un √©quilibre entre la pr√©cision et le rappel.
        """, unsafe_allow_html=True)

        # Affichage des graphiques dans les colonnes
        col1, col2, col3, col4 = st.columns(4)
        for col, fig in zip([col1, col2, col3, col4], figures):
            col.plotly_chart(fig, use_container_width=True)

    with st.expander("üìä Implication des m√©triques dans notre classification de rapports m√©dicaux", expanded=True):
        st.markdown(
            """
            ## Implication des m√©triques dans notre probl√®me de classification de rapports m√©dicaux
            
            Dans notre projet de classification de rapports m√©dicaux, les m√©triques d‚Äô√©valuation jouent un r√¥le essentiel pour mesurer la qualit√© de nos mod√®les de classification. Voici comment chacune d'elles s‚Äôapplique √† notre contexte :
            
            ### 1Ô∏è‚É£ Accuracy (Exactitude)
            - Mesure la proportion de rapports m√©dicaux correctement classifi√©s sur l‚Äôensemble des pr√©dictions.
            - **Exemple** : Si nous avons 100 rapports et que 90 sont correctement class√©s, l‚Äôaccuracy est de 90%.
            - **Probl√®me potentiel** : Un mod√®le qui pr√©dit toujours la classe majoritaire peut avoir une haute accuracy sans √™tre efficace.
            
            ### 2Ô∏è‚É£ Precision (Pr√©cision)
            - Indique combien de rapports pr√©dits dans une cat√©gorie sp√©cifique sont r√©ellement corrects.
            - **Exemple** : Sur 50 rapports class√©s comme "Neoplasms", 40 sont corrects ‚Üí Pr√©cision = 40/50 = 80%.
            - **Importance** : √âviter les faux positifs est crucial, par exemple, pour ne pas diagnostiquer √† tort une maladie grave.
            
            ### 3Ô∏è‚É£ Recall (Rappel)
            - Mesure la proportion de rapports d‚Äôune cat√©gorie sp√©cifique bien d√©tect√©s.
            - **Exemple** : Sur 60 rapports de "Cardiovascular Diseases", le mod√®le n‚Äôen identifie que 45 ‚Üí Rappel = 45/60 = 75%.
            - **Importance** : Un rappel √©lev√© est essentiel pour ne pas rater des diagnostics critiques.
            
            ### 4Ô∏è‚É£ F1 Score
            - C‚Äôest un **compromis entre pr√©cision et rappel**, surtout utile en cas de d√©s√©quilibre des classes.
            - **Exemple** : Si un mod√®le a une pr√©cision de 80% et un rappel de 75%, son F1 Score sera d‚Äôenviron 77%.
            - **Importance** : Assure un bon √©quilibre et √©vite de favoriser une m√©trique au d√©triment de l‚Äôautre.
            
            ---
            
            ## Conclusion et choix des m√©triques adapt√©es
            - **Si nous voulons minimiser les faux positifs** (√©viter un mauvais diagnostic) ‚Üí **Privil√©gier la pr√©cision**.
            - **Si nous voulons minimiser les faux n√©gatifs** (√©viter de rater un diagnostic important) ‚Üí **Privil√©gier le rappel**.
            - **Si nous cherchons un compromis √©quilibr√©** ‚Üí **Utiliser le F1 Score**.
            - **L‚Äôaccuracy peut √™tre trompeuse**, donc elle sera utilis√©e avec prudence.
            
            üí° **Notre choix** : Nous privil√©gions le **F1 Score** pour garantir un bon compromis entre rappel et pr√©cision, tout en surveillant les autres m√©triques pour ajuster nos mod√®les.
            """
        )


# Fonction pour charger le pipeline sauvegard√©
@st.cache_data
def load_saved_pipeline(nom_fichier, chemin):
    """
    Charge un pipeline sauvegard√© √† partir d'un fichier.

    Args:
        nom_fichier (str): Nom du fichier contenant le mod√®le sauvegard√©.
        chemin (str): R√©pertoire o√π se trouve le fichier.

    Returns:
        Pipeline: Le pipeline charg√© depuis le fichier.
    """
    chemin_complet = os.path.join(chemin, nom_fichier)
    
    try:
        pipeline = joblib.load(chemin_complet)
        #st.write(f"‚úÖ Mod√®le charg√© avec succ√®s depuis {chemin_complet}")
        return pipeline
    except FileNotFoundError:
        st.write(f"‚ùå Erreur : Aucun mod√®le trouv√© √† {chemin_complet}")
        return None
    except Exception as e:
        st.write(f"‚ùå Erreur lors du chargement du mod√®le : {e}")
        return None

# Fonction pour afficher l'onglet de pr√©diction
def display_prediction(pipeline):
    st.title("Pr√©diction")
    option = st.selectbox("Choisissez la m√©thode de saisie des donn√©es :", ["Saisie manuelle", "Charger un fichier CSV"], placeholder="S√©lectionnez la m√©thode de saisie...",index=None)
    if option == "Saisie manuelle":
        st.subheader("Saisie manuelle des donn√©es")
        input_data = st.text_area("üìù Collez un r√©sum√© m√©dical pour la pr√©diction :", "")
        if input_data.strip():  # V√©rifie que l'entr√©e n'est pas vide
            if st.button("Pr√©dire"):
                # Pr√©diction de la classe
                y_pred = pipeline.predict([input_data])[0]

                # Pr√©diction des probabilit√©s associ√©es √† chaque classe
                y_proba = pipeline.predict_proba([input_data])[0]

                # R√©cup√©rer la probabilit√© associ√©e √† la classe pr√©dite
                class_index = list(pipeline.classes_).index(y_pred)
                confidence = y_proba[class_index] * 100  # Convertir en pourcentage

                # Affichage du r√©sultat
                st.success(f"üîç Classe pr√©dite : **{y_pred}**")
                st.info(f"üìä Probabilit√© de cette classe : **{confidence:.2f}%**")
        else:
            st.warning("‚ö†Ô∏è Veuillez entrer un texte avant de lancer la pr√©diction.")

    elif option == "Charger un fichier CSV":
        st.subheader("Chargement de donn√©es √† partir d'un fichier CSV")
        uploaded_file = st.file_uploader("Choisissez un fichier CSV", type=["csv"])
        if uploaded_file is not None:
            data = pd.read_csv(uploaded_file)
            st.write("Aper√ßu des donn√©es charg√©es :")
            st.dataframe(data.head(),use_container_width=True)
            # V√©rifier si la colonne cleaned_medical_abstract existe
            if "cleaned_medical_abstract" in data.columns:
                if st.button("Pr√©dire pour tous les textes"):
                    with st.spinner("‚è≥ Pr√©diction en cours, veuillez patienter..."):

                        # Pr√©dire les classes
                        predictions = pipeline.predict(data["cleaned_medical_abstract"])
                        probabilities = pipeline.predict_proba(data["cleaned_medical_abstract"]).max(axis=1) * 100  # Probabilit√© max
                        
                        # Ajouter les colonnes de pr√©diction
                        data["label_predicted"] = predictions
                        data["probability"] = probabilities
                        
                        # Affichage des r√©sultats
                        st.write("‚úÖ Pr√©dictions effectu√©es avec succ√®s !")
                        st.dataframe(data.head(), use_container_width=True)
                        
                        # Permettre le t√©l√©chargement du fichier mis √† jour
                        csv = data.to_csv(index=False).encode('utf-8')
                        st.download_button("üì• T√©l√©charger les r√©sultats", csv, "predictions.csv", "text/csv")
            else:
                st.error("‚ùå Le fichier CSV doit contenir une colonne 'cleaned_medical_abstract'.")


# Fonction pour tracer la distribution
def plot_label_distribution(data, column_name):
    label_counts = data[column_name].value_counts()
    label_percentage = label_counts / label_counts.sum() * 100

    data_pie = pd.DataFrame({
        'Label': label_counts.index,
        'Count': label_counts.values,
        'Percentage': label_percentage.values
    })
    
    # D√©finir une palette de couleurs
    colors = sns.color_palette("viridis", len(data_pie)).as_hex()
    
    # Cr√©ation de la figure
    fig = make_subplots(rows=1, cols=2, 
                        specs=[[{'type': 'domain'}, {'type': 'xy'}]],
                        subplot_titles=['Pie Chart ü•ß', 'Bar Chart üìä'])

    # Ajout du pie chart
    fig.add_trace(
        go.Pie(
            labels=data_pie['Label'], 
            values=data_pie['Count'],
            name='Labels', 
            marker=dict(colors=colors),
            showlegend=True
        ),
        row=1, col=1
    )
    
    # Ajout du bar chart
    fig.add_trace(
        go.Bar(
            x=data_pie['Label'], 
            y=data_pie['Count'], 
            name='Labels', 
            marker=dict(color=colors),
            text=[f"{count} ({percentage:.1f}%)" for count, percentage in zip(data_pie['Count'], data_pie['Percentage'])],
            textposition='auto'
        ),
        row=1, col=2
    )
    
    fig.update_layout(
        title=f'Distribution of Labels in "{column_name}"',
        title_x=0.5
    )
    
    return fig

# Fonction pour tracer la distribution des longueurs de texte
def plot_text_length_box_swarm_px(df, length_column='original_length', label_column='condition_label'):
    fig = px.box(df, x=label_column, y=length_column, points="all", color=label_column, 
                 title="üìè Distribution des longueurs de texte par cat√©gorie m√©dicale üìä", 
                 labels={length_column: "Longueur du Texte ‚úçÔ∏è", label_column: "Condition M√©dicale üè•"}, 
                 template="simple_white")
    return fig

def add_text_length_column(df, text_column='medical_abstract', length_column='original_length'):
    """
    Ajoute une colonne sp√©cifi√©e au dataset avec la longueur des textes d'une colonne donn√©e.
    
    Args:
    - df (pd.DataFrame): Le DataFrame contenant les donn√©es.
    - text_column (str): Nom de la colonne contenant les textes.
    - length_column (str): Nom de la colonne o√π sera stock√©e la longueur des textes.
    
    Returns:
    - pd.DataFrame: DataFrame avec la nouvelle colonne contenant les longueurs des textes.
    """
    if text_column not in df.columns:
        raise ValueError(f"La colonne '{text_column}' n'existe pas dans le DataFrame.")
    
    df[length_column] = df[text_column].apply(lambda x: len(str(x)))
    return df

# Fonction pour calculer les statistiques descriptives
def text_length_statistics(df, length_column='original_length', label_column='condition_label'):
    stats_df = df.groupby(label_column)[length_column].describe().reset_index()
    stats_df.columns = ['Condition M√©dicale', 'Nombre de textes', 'Moyenne', '√âcart-Type', 'Min', 'Q1 (25%)', 'M√©diane (50%)', 'Q3 (75%)', 'Max']
    return stats_df

# Fonction pour afficher l'histogramme des longueurs de texte
def plot_text_length_histogram(df, length_column='original_length', label_column='condition_label'):
    fig = px.histogram(df, x=length_column, color=label_column, barmode="overlay", nbins=50,
                       title="üìè Distribution des longueurs de texte par cat√©gorie m√©dicale üìä",
                       labels={length_column: "Longueur du Texte ‚úçÔ∏è", label_column: "Condition M√©dicale üè•"},
                       template="simple_white")
    return fig

# Fonction pour afficher le Box + Swarm plot
def plot_text_length_box_swarm(df, length_column='original_length', label_column='condition_label'):
    fig, ax = plt.subplots(figsize=(12, 6))
    sns.boxplot(data=df, x=label_column, y=length_column, showfliers=False, width=0.5, boxprops={'facecolor':'lightgray'}, ax=ax)
    sns.swarmplot(data=df, x=label_column, y=length_column, color='black', alpha=0.7, size=4, ax=ax)
    ax.set_title("üìä Distribution des longueurs de texte par cat√©gorie m√©dicale (Box + Swarm)")
    ax.set_xlabel("Condition M√©dicale üè•")
    ax.set_ylabel("Longueur du Texte ‚úçÔ∏è")
    plt.xticks(rotation=30)
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    return fig


# Fonction pour afficher l'onglet EDA
def display_eda(data):
    st.title("Exploratory Data Analysis (EDA)")

    st.header("_Analyse des Donn√©es M√©dicales Report_ üè• :bar_chart: :clipboard: :blue[üìä] :orange[üî•]", divider='rainbow')

    st.subheader("üî¨ **Visualisation du Jeu de Donn√©es M√©dicales** üìäüè•")

    st.dataframe(
        data.head(), 
        use_container_width=True,  # Ajuste la largeur √† celle du conteneur
        #height=300  # Ajuste la hauteur pour √©viter le scroll excessif
    )
    # Colonne cible √† exclure
    text_column, length_column, target_column ='medical_abstract', 'original_length', 'condition_label'

    # Affichage des visualisations dans un expander
    with st.expander("üìä Show Label Distribution Graphs üîç"):
        fig = plot_label_distribution(data, target_column)
        st.plotly_chart(fig)

    # S√©lection des colonnes pour la distribution des longueurs de texte
    with st.expander("üìè Show Text Length Distribution üìä"):
        data = add_text_length_column(data, text_column='medical_abstract', length_column='original_length')  # Ajout de la colonne '
        fig_text_length = plot_text_length_box_swarm_px(data, length_column, target_column)
        st.plotly_chart(fig_text_length)

    # Affichage des statistiques descriptives
    with st.expander("üìà Show Text Length Statistics üè•"):
        stats_df = text_length_statistics(data, length_column, target_column)
        st.dataframe(stats_df, use_container_width=True)

    with st.expander("üìä Show Text Length Histogram üìè"):
        fig_hist = plot_text_length_histogram(data, length_column, target_column)
        st.plotly_chart(fig_hist)
    
    with st.expander("üìä Show Text Length Box + Swarm üìè"):
        fig_swarm = plot_text_length_box_swarm(data, length_column, target_column)
        st.pyplot(fig_swarm)

# Interface principale
def main():
    dataset_path = "/Users/surelmanda/Downloads/My-Projects-Data/Project-Data-Scientist/Machine-Leaning-Local/MANTU_AI_Technical_Test/data/original_data"
    path_rapport = '/Users/surelmanda/Downloads/My-Projects-Data/Project-Data-Scientist/Machine-Leaning-Local/MANTU_AI_Technical_Test/metrics'
    nom_fichier_pipeline = "best_pipeline.pkl"
    path_model = "/Users/surelmanda/Downloads/My-Projects-Data/Project-Data-Scientist/Machine-Leaning-Local/MANTU_AI_Technical_Test/model"

    data = load_dataset(dataset_path)
    display_sidebar()
    # model = load_model(model_path)
    tab1, tab2, tab3, tab4 = st.tabs(["1 - üè† Pr√©sentation", "2 - üìà Exploratory Data Analysis", "3 - üèãÔ∏è‚Äç‚ôÇÔ∏è Global Performance", "4 - üèÉ‚Äç‚ôÇÔ∏è Prediction"])
    with tab1:
        display_presentation()
    with tab2:
         display_eda(data)
         #st.write('Okey!!!!')   
    with tab3:
         display_global_performance(path_rapport)
    with tab4:
         pipeline = load_saved_pipeline(nom_fichier_pipeline, path_model)
         display_prediction(pipeline)


if __name__ == "__main__":
    main()
